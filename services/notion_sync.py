"""
ìƒˆë¡œìš´ Notion ìº˜ë¦°ë” ë™ê¸°í™” ì„œë¹„ìŠ¤
ê°„ë‹¨í•˜ê³  ê¹”ë”í•œ êµ¬ì¡°ë¡œ ì¬ì‘ì„±
"""

import os
import json
import logging
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any

# Notion API í´ë˜ìŠ¤
class NotionAPI:
    """Notion API í˜¸ì¶œì„ ë‹´ë‹¹í•˜ëŠ” ê°„ë‹¨í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, token: str):
        self.token = token
        self.base_url = "https://api.notion.com/v1"
        self.headers = {
            'Authorization': f'Bearer {token}',
            'Notion-Version': '2022-06-28',
            'Content-Type': 'application/json'
        }
        # ë¬¸ì œ ìˆëŠ” ë°ì´í„°ë² ì´ìŠ¤ ë¸”ë™ë¦¬ìŠ¤íŠ¸ (ë©”ëª¨ë¦¬ ì €ì¥)
        self.blacklisted_databases = set()
    
    def search_databases(self) -> List[Dict]:
        """ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰"""
        try:
            import requests
            
            # Searching Notion databases
            
            response = requests.post(
                f"{self.base_url}/search",
                headers=self.headers,
                json={
                    "filter": {
                        "property": "object",
                        "value": "database"
                    }
                },
                timeout=10
            )
            
            print(f"ğŸ“¡ [NOTION API] Response status: {response.status_code}")
            
            if response.status_code == 200:
                results = response.json().get('results', [])
                print(f"âœ… [NOTION API] Found {len(results)} databases")
                return results
            else:
                print(f"âŒ [NOTION API] Database search failed: {response.status_code}")
                print(f"âŒ [NOTION API] Error response: {response.text}")
                return []
                
        except Exception as e:
            print(f"âŒ Error searching databases: {e}")
            return []
    
    def query_database(self, database_id: str, page_size: int = 50, start_cursor: str = None) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ì˜ í˜ì´ì§€ë“¤ ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì›)"""
        try:
            import requests
            from datetime import datetime, timedelta
            
            # ë¨¼ì € ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ í™•ì¸ (ë°©ì–´ ë¡œì§)
            try:
                schema_response = requests.get(
                    f"{self.base_url}/databases/{database_id}",
                    headers=self.headers,
                    timeout=10
                )
                if schema_response.status_code != 200:
                    print(f"âš ï¸ Database schema check failed for {database_id}: {schema_response.status_code}")
                    print(f"Response: {schema_response.text}")
                    return {'results': [], 'has_more': False, 'next_cursor': None, 'total_count': 0}
                    
                schema = schema_response.json()
                properties = schema.get('properties', {})
                print(f"âœ… Database {database_id} has {len(properties)} properties")
                
            except Exception as schema_error:
                print(f"âš ï¸ Could not check database schema for {database_id}: {schema_error}")
                # Continue with query anyway
            
            # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ê¸° (ì„±ëŠ¥ ìµœì í™”)
            three_months_ago = (datetime.now() - timedelta(days=90)).isoformat()
            
            # ì•ˆì „í•œ ì¿¼ë¦¬ - ìŠ¤í‚¤ë§ˆ í™•ì¸ í›„ ì •ë ¬ ì„¤ì •
            query_payload = {
                "page_size": page_size
            }
            
            # ìŠ¤í‚¤ë§ˆì—ì„œ ë‚ ì§œ í”„ë¡œí¼í‹°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ìˆìœ¼ë©´ ì •ë ¬ì— ì‚¬ìš©
            try:
                if 'schema' in locals() and 'properties' in locals():
                    # ë‚ ì§œ íƒ€ì… í”„ë¡œí¼í‹° ì°¾ê¸°
                    date_property_name = None
                    for prop_name, prop_data in properties.items():
                        if prop_data.get('type') == 'date':
                            date_property_name = prop_name
                            break
                    
                    if date_property_name:
                        # ë‚ ì§œ í”„ë¡œí¼í‹°ë¡œ ì •ë ¬
                        query_payload["sorts"] = [
                            {
                                "property": date_property_name,
                                "direction": "descending"
                            }
                        ]
                        print(f"âœ… Using date property '{date_property_name}' for sorting")
                    else:
                        # ë‚ ì§œ í”„ë¡œí¼í‹°ê°€ ì—†ìœ¼ë©´ timestampë¡œ ì •ë ¬
                        query_payload["sorts"] = [
                            {
                                "timestamp": "last_edited_time",
                                "direction": "descending"
                            }
                        ]
                        # Using last_edited_time for sorting
                else:
                    # ìŠ¤í‚¤ë§ˆ í™•ì¸ ì‹¤íŒ¨ì‹œ ì•ˆì „í•œ ê¸°ë³¸ê°’
                    query_payload["sorts"] = [
                        {
                            "timestamp": "last_edited_time",
                            "direction": "descending"
                        }
                    ]
                    print("âš ï¸ Schema not available, using last_edited_time for sorting")
            except Exception as sort_error:
                print(f"âš ï¸ Error setting up sort: {sort_error}")
                # ì •ë ¬ ì—†ì´ ì§„í–‰
                pass
            
            if start_cursor:
                query_payload["start_cursor"] = start_cursor
            
            response = requests.post(
                f"{self.base_url}/databases/{database_id}/query",
                headers=self.headers,
                json=query_payload,
                timeout=30  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
            )
            
            if response.status_code == 200:
                result = response.json()
                return {
                    'results': result.get('results', []),
                    'has_more': result.get('has_more', False),
                    'next_cursor': result.get('next_cursor'),
                    'total_count': len(result.get('results', []))
                }
            else:
                print(f"âŒ Database query failed for {database_id}: {response.status_code}")
                print(f"Response: {response.text}")
                
                # 400 ì—ëŸ¬ì¸ ê²½ìš° ë” ìì„¸í•œ ë¶„ì„
                if response.status_code == 400:
                    try:
                        error_data = response.json()
                        error_code = error_data.get('code')
                        error_message = error_data.get('message', '')
                        
                        if 'property' in error_message.lower() and 'date' in error_message.lower():
                            # Date property error detected
                            print(f"Error: {error_message}")
                            # ì´ ë°ì´í„°ë² ì´ìŠ¤ëŠ” ë‚ ì§œ ì†ì„±ì´ ì—†ê±°ë‚˜ ì˜ëª»ëœ êµ¬ì¡°
                        
                    except Exception as parse_error:
                        print(f"Could not parse error response: {parse_error}")
                
                return {'results': [], 'has_more': False, 'next_cursor': None, 'total_count': 0}
                
        except Exception as e:
            print(f"âŒ Error querying database {database_id}: {e}")
            
            # íŠ¹ì • ì—ëŸ¬ íŒ¨í„´ ê°ì§€
            error_str = str(e).lower()
            if 'property' in error_str and ('date' in error_str or 'name' in error_str or 'id' in error_str):
                # Property access error
                print("This database may have an incompatible schema or may be inaccessible")
                # ë¬¸ì œ ìˆëŠ” ë°ì´í„°ë² ì´ìŠ¤ëŠ” ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                self._add_to_blacklist(database_id, "property_access_error")
                
            elif 'not found' in error_str or '404' in error_str:
                print(f"ğŸ—‘ï¸ Database {database_id} not found - may have been deleted")
                self._add_to_blacklist(database_id, "not_found")
                
            elif 'unauthorized' in error_str or '403' in error_str:
                print(f"ğŸ”’ Database {database_id} access denied")
                self._add_to_blacklist(database_id, "access_denied")
                
            return {'results': [], 'has_more': False, 'next_cursor': None, 'total_count': 0}
    
    def _add_to_blacklist(self, database_id: str, reason: str):
        """ë¬¸ì œ ìˆëŠ” ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"""
        self.blacklisted_databases.add(database_id)
        print(f"ğŸš« Database {database_id} added to blacklist (reason: {reason})")
    
    def _is_blacklisted(self, database_id: str) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸"""
        return database_id in self.blacklisted_databases
    
    def query_database_safe(self, database_id: str, page_size: int = 50, start_cursor: str = None) -> Dict:
        """ì•ˆì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ - ë¸”ë™ë¦¬ìŠ¤íŠ¸ í™•ì¸"""
        if self._is_blacklisted(database_id):
            print(f"â­ï¸ Skipping blacklisted database {database_id}")
            return {'results': [], 'has_more': False, 'next_cursor': None, 'total_count': 0}
        
        return self.query_database(database_id, page_size, start_cursor)


# Notion ìº˜ë¦°ë” ë™ê¸°í™” í´ë˜ìŠ¤
class NotionCalendarSync:
    """Notionê³¼ NotionFlow ìº˜ë¦°ë” ë™ê¸°í™”"""
    
    def __init__(self):
        self.logger = logging.getLogger('NotionSync')
    
    def get_user_notion_token(self, user_id: str) -> Optional[str]:
        """ì‚¬ìš©ìì˜ Notion í† í° ê°€ì ¸ì˜¤ê¸°"""
        try:
            from utils.config import config
            from utils.uuid_helper import normalize_uuid
            
            # UUID ì •ê·œí™” (í†µì¼ëœ í˜•ì‹ - í•˜ì´í”ˆ ì—†ìŒ)
            normalized_user_id = normalize_uuid(user_id)
            # Searching for user token
            
            # í†µì¼ëœ í˜•ì‹ ì‚¬ìš© - ë” ì´ìƒ ì—¬ëŸ¬ í˜•ì‹ì„ ì‹œë„í•˜ì§€ ì•ŠìŒ
            # Using unified user format
            
            supabase = config.get_client_for_user(user_id)
            
            if not supabase:
                print("âŒ Supabase client not available")
                return None
            
            # 1. calendar_sync_configs í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ (ìƒˆë¡œìš´ ì£¼ìš” ì €ì¥ì†Œ)
            # Checking sync configs for user
            config_result = supabase.table('calendar_sync_configs').select('*').eq(
                'user_id', normalized_user_id
            ).eq('platform', 'notion').execute()
            
            if config_result.data:
                # Found sync config data
                creds = config_result.data[0].get('credentials', {})
                if isinstance(creds, dict):
                    token = creds.get('access_token')
                    if token:
                        print(f"âœ… [TOKEN] Found Notion token in calendar_sync_configs: {token[:20]}...")
                        return token
                    else:
                        print(f"âš ï¸ [TOKEN] No access_token in credentials: {creds.keys()}")
                else:
                    print(f"âš ï¸ [TOKEN] Credentials not in dict format: {type(creds)}")
            else:
                print(f"âš ï¸ [TOKEN] No calendar_sync_configs found for Notion user {normalized_user_id}")
            
            # 2. platform_connections í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ (ë°±ì—… - access_token ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìŒ)
            try:
                result = supabase.table('platform_connections').select('*').eq(
                    'user_id', user_id
                ).eq('platform', 'notion').eq('is_connected', True).execute()
                
                if result.data:
                    print(f"âœ… Found Notion connection in platform_connections but no token field")
                    # platform_connectionsì—ëŠ” í† í°ì´ ì—†ìœ¼ë¯€ë¡œ oauth_tokensì—ì„œ ë‹¤ì‹œ í™•ì¸
            except:
                pass
            
            # 3. oauth_tokens í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ (ë°±ì—… - ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ë¬¸ì œ ìˆì„ ìˆ˜ ìˆìŒ)
            try:
                oauth_result = supabase.table('oauth_tokens').select('access_token').eq(
                    'user_id', user_id
                ).eq('platform', 'notion').execute()
                
                if oauth_result.data and oauth_result.data[0].get('access_token'):
                    token = oauth_result.data[0].get('access_token')
                    print(f"âœ… Found Notion token in oauth_tokens (backup): {token[:20]}...")
                    return token
            except Exception as oauth_error:
                print(f"âš ï¸ Could not check oauth_tokens (expected due to constraints): {oauth_error}")
            
            # 4. Session fallback (if database storage failed)
            try:
                from flask import session
                if session and session.get('platform_tokens', {}).get('notion', {}).get('access_token'):
                    token = session['platform_tokens']['notion']['access_token']
                    # Using session token
                    return token
            except Exception as session_error:
                print(f"âš ï¸ Could not check session tokens: {session_error}")
            
            print("âŒ No Notion token found in any table or session")
            return None
            
        except Exception as e:
            print(f"âŒ Error getting Notion token: {e}")
            # Try session as final fallback
            try:
                from flask import session
                if session and session.get('platform_tokens', {}).get('notion', {}).get('access_token'):
                    token = session['platform_tokens']['notion']['access_token']
                    # Using token fallback
                    return token
            except:
                pass
            import traceback
            traceback.print_exc()
            return None
    
    def find_calendar_databases(self, notion_api: NotionAPI) -> List[Dict]:
        """ìº˜ë¦°ë”/ì¼ì • ê´€ë ¨ ë°ì´í„°ë² ì´ìŠ¤ ì°¾ê¸°"""
        databases = notion_api.search_databases()
        calendar_dbs = []
        
        for db in databases:
            # ë°ì´í„°ë² ì´ìŠ¤ ì œëª© ì¶”ì¶œ
            title = self._get_db_title(db)
            
            # ìº˜ë¦°ë” ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
            calendar_keywords = ['calendar', 'schedule', 'event', 'task', 'todo', 
                               'ì¼ì •', 'ìº˜ë¦°ë”', 'ìŠ¤ì¼€ì¤„', 'í• ì¼', 'ì—…ë¬´']
            
            if any(keyword in title.lower() for keyword in calendar_keywords):
                calendar_dbs.append(db)
                # Found calendar database
            
            # ë‚ ì§œ ì†ì„±ì´ ìˆëŠ”ì§€ ì²´í¬
            elif self._has_date_property(db):
                calendar_dbs.append(db)
                # Found database with date property
        
        return calendar_dbs
    
    def get_user_calendar_id(self, user_id: str) -> Optional[str]:
        """Get the correct calendar_id for a user from selected_calendars table"""
        try:
            from utils.config import config
            from utils.uuid_helper import normalize_uuid
            
            # Normalize user_id for consistency
            normalized_user_id = normalize_uuid(user_id)
            
            # Use admin client to bypass RLS
            supabase = config.supabase_admin if hasattr(config, 'supabase_admin') and config.supabase_admin else config.get_client_for_user(user_id)
            
            if not supabase:
                print(f"âŒ [CALENDAR_ID] No Supabase client for user {user_id}")
                return None
            
            # Fallback: Use first available calendar for the user
            try:
                calendars_result = supabase.table('calendars').select('id, name').eq('owner_id', user_id).eq('is_active', True).limit(1).execute()
                if calendars_result.data:
                    calendar_id = calendars_result.data[0]['id']
                    calendar_name = calendars_result.data[0]['name']
                    print(f"âœ… [CALENDAR_ID] Using first available calendar for user {user_id}: {calendar_name} ({calendar_id})")
                    return calendar_id
                else:
                    print(f"âš ï¸ [CALENDAR_ID] No active calendars found for user {user_id}")
                    return None
            except Exception as calendar_error:
                print(f"âŒ [CALENDAR_ID] Error querying user_calendars: {calendar_error}")
                return None
                
        except Exception as e:
            print(f"âŒ [CALENDAR_ID] Error getting calendar_id for user {user_id}: {e}")
            return None
    
    def _create_default_calendar(self, user_id: str, supabase) -> Optional[Dict]:
        """Create a default calendar for user if none exists"""
        try:
            import uuid
            from utils.uuid_helper import normalize_uuid
            
            normalized_user_id = normalize_uuid(user_id)
            
            default_calendar_data = {
                'id': str(uuid.uuid4()),
                'owner_id': normalized_user_id,
                'name': 'My Notion Calendar',
                'type': 'notion',
                'color': '#3B82F6',
                'description': 'Auto-created calendar for Notion sync',
                'is_active': True,
                'public_access': False,
                'allow_editing': True,
                'created_at': datetime.now(timezone.utc).isoformat(),
                'updated_at': datetime.now(timezone.utc).isoformat()
            }
            
            result = supabase.table('calendars').insert(default_calendar_data).execute()
            
            if result.data:
                print(f"âœ… [CALENDAR_ID] Created default calendar: {result.data[0]['id']}")
                return result.data[0]
            else:
                print(f"âŒ [CALENDAR_ID] Failed to create default calendar")
                return None
                
        except Exception as e:
            print(f"âŒ [CALENDAR_ID] Error creating default calendar: {e}")
            return None

    def sync_to_calendar(self, user_id: str, calendar_id: str = None) -> Dict[str, Any]:
        """Notion ë°ì´í„°ë¥¼ NotionFlow ìº˜ë¦°ë”ë¡œ ë™ê¸°í™” - ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”"""
        try:
            # If no calendar_id provided, get it from database
            if not calendar_id:
                calendar_id = self.get_user_calendar_id(user_id)
                if not calendar_id:
                    return {
                        'success': False,
                        'error': 'ë™ê¸°í™”í•  ìº˜ë¦°ë”ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ ì—°ê²° í˜ì´ì§€ì—ì„œ ìº˜ë¦°ë”ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.',
                        'synced_events': 0
                    }

            print(f"ğŸš€ [BATCH SYNC] Starting optimized Notion sync for user {user_id}, calendar {calendar_id}")

            # 1. Notion í† í° í™•ì¸
            token = self.get_user_notion_token(user_id)
            # Token validation complete

            if not token:
                print(f"âŒ [NOTION] No token found for user {user_id}")
                return {
                    'success': False,
                    'error': 'No Notion token found',
                    'synced_events': 0
                }

            # 2. Notion API ì´ˆê¸°í™”
            # Initializing Notion API
            notion_api = NotionAPI(token)

            # 3. ìº˜ë¦°ë” ë°ì´í„°ë² ì´ìŠ¤ ì°¾ê¸°
            # Searching calendar databases
            calendar_dbs = self.find_calendar_databases(notion_api)
            print(f"ğŸ“š [NOTION] Found {len(calendar_dbs)} calendar databases")

            if not calendar_dbs:
                print(f"âš ï¸ [NOTION] No calendar databases found in Notion workspace")
                return {
                    'success': True,
                    'message': 'No calendar databases found in Notion',
                    'synced_events': 0
                }

            # 4. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì´ë²¤íŠ¸ ì¶”ì¶œ ë° ë™ê¸°í™”
            total_synced = 0
            max_initial_load = 50  # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ì¦ê°€
            batch_size = 10  # ë°°ì¹˜ í¬ê¸°
            batch_events = []  # ë°°ì¹˜ ì €ì¥ìš© ì„ì‹œ ë¦¬ìŠ¤íŠ¸

            for db in calendar_dbs:
                db_id = db['id']
                db_title = self._get_db_title(db)

                # Processing database in batches

                # í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ í˜ì´ì§€ë“¤ ì¡°íšŒ
                start_cursor = None
                db_synced = 0

                while True:
                    # í•œ ë²ˆì— 25ê°œì”© ì²˜ë¦¬ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± ì¦ê°€)
                    result = notion_api.query_database_safe(db_id, page_size=25, start_cursor=start_cursor)
                    pages = result.get('results', [])

                    if not pages:
                        break

                    print(f"ğŸ“„ Processing {len(pages)} pages from {db_title}")

                    # ë°°ì¹˜ ì²˜ë¦¬ ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë° DB ì—°ê²° ìµœì í™”
                    for page in pages:
                        # Notion í˜ì´ì§€ë¥¼ ìº˜ë¦°ë” ì´ë²¤íŠ¸ë¡œ ë³€í™˜
                        event = self._convert_page_to_event(page, calendar_id, user_id)
                        if event:
                            batch_events.append(event)

                        # ë°°ì¹˜ê°€ ì°¼ê±°ë‚˜ ë§ˆì§€ë§‰ í˜ì´ì§€ë©´ ì €ì¥
                        if len(batch_events) >= batch_size:
                            saved_count = self._save_events_batch(batch_events)
                            total_synced += saved_count
                            db_synced += saved_count
                            print(f"ğŸ’¾ [BATCH] Saved {saved_count}/{len(batch_events)} events")
                            batch_events.clear()  # ë°°ì¹˜ ì´ˆê¸°í™”

                        # ì´ˆê¸° ë¡œë“œ ì œí•œ í™•ì¸
                        if total_synced >= max_initial_load:
                            print(f"âš¡ Initial load limit reached ({max_initial_load} events). Breaking early.")
                            break

                    # ì´ˆê¸° ë¡œë“œ ì œí•œ í™•ì¸
                    if total_synced >= max_initial_load:
                        print(f"âš¡ Initial load limit reached ({max_initial_load} events). Remaining data will be synced in background.")
                        break

                    # ë‹¤ìŒ í˜ì´ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if not result.get('has_more', False):
                        break

                    start_cursor = result.get('next_cursor')

                # ë‚¨ì€ ë°°ì¹˜ ì´ë²¤íŠ¸ë“¤ ì €ì¥
                if batch_events:
                    saved_count = self._save_events_batch(batch_events)
                    total_synced += saved_count
                    db_synced += saved_count
                    print(f"ğŸ’¾ [BATCH FINAL] Saved final {saved_count}/{len(batch_events)} events")
                    batch_events.clear()

                print(f"ğŸ“Š Database {db_title}: {db_synced} events synced")

                # ì´ˆê¸° ë¡œë“œ ì œí•œì— ë„ë‹¬í–ˆìœ¼ë©´ ì¤‘ë‹¨
                if total_synced >= max_initial_load:
                    break

            result = {
                'success': True,
                'synced_events': total_synced,
                'databases_processed': len(calendar_dbs),
                'limited_initial_load': total_synced >= max_initial_load,
                'message': f"Successfully synced {total_synced} events" +
                          (f" (limited to {max_initial_load} for initial load)" if total_synced >= max_initial_load else "")
            }

            # ì´ˆê¸° ë¡œë“œ ì œí•œì— ë„ë‹¬í•œ ê²½ìš° ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‚˜ë¨¸ì§€ ë™ê¸°í™” ì˜ˆì•½
            if total_synced >= max_initial_load:
                try:
                    self._schedule_background_sync(user_id, calendar_id, token)
                    result['background_sync_scheduled'] = True
                except Exception as bg_error:
                    print(f"âš ï¸ Failed to schedule background sync: {bg_error}")
                    result['background_sync_scheduled'] = False

            # PERFORMANCE OPTIMIZATION: ì—°ë™ ì§í›„ ìºì‹œ ì›Œë°ì—…ì„ ìœ„í•œ ë°±ê·¸ë¼ìš´ë“œ í”„ë¦¬ë¡œë”©
            try:
                self._schedule_cache_warmup(user_id, calendar_id)
            except Exception as cache_error:
                print(f"âš ï¸ Cache warmup scheduling failed: {cache_error}")

            return result

        except Exception as e:
            print(f"âŒ Sync failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'synced_events': 0
            }
    
    def _get_db_title(self, database: Dict) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ ì œëª© ì¶”ì¶œ"""
        try:
            title_obj = database.get('title', [])
            if title_obj and len(title_obj) > 0:
                return title_obj[0].get('plain_text', 'Untitled')
            return 'Untitled'
        except:
            return 'Untitled'
    
    def _has_date_property(self, database: Dict) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ì— ë‚ ì§œ ì†ì„±ì´ ìˆëŠ”ì§€ í™•ì¸"""
        try:
            properties = database.get('properties', {})
            for prop_name, prop_data in properties.items():
                if prop_data.get('type') == 'date':
                    return True
            return False
        except:
            return False
    
    def _convert_page_to_event(self, page: Dict, calendar_id: str, user_id: str) -> Optional[Dict]:
        """Notion í˜ì´ì§€ë¥¼ NotionFlow ì´ë²¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            properties = page.get('properties', {})
            
            # 1. ì œëª© ì¶”ì¶œ
            title = self._extract_title(properties)
            if not title:
                return None
            
            # 2. ë‚ ì§œ ì¶”ì¶œ
            date_info = self._extract_date(properties)
            if not date_info:
                return None
            
            # 3. ì„¤ëª… ì¶”ì¶œ
            description = self._extract_description(properties)
            
            # 4. ë‚ ì§œ/ì‹œê°„ ì •ê·œí™”
            start_datetime, end_datetime = self._normalize_datetime(date_info)
            
            # 5. NotionFlow ì´ë²¤íŠ¸ ìƒì„±
            event = {
                'calendar_id': calendar_id,
                'user_id': user_id,
                'title': title,
                'description': description or '',
                'start_datetime': start_datetime,
                'end_datetime': end_datetime,
                'all_day': date_info.get('all_day', False),
                'external_id': f"notion_{page['id']}",
                'external_platform': 'notion',
                'created_at': datetime.now(timezone.utc).isoformat(),
                'updated_at': datetime.now(timezone.utc).isoformat(),
                'metadata': {
                    'notion_page_id': page['id'],
                    'notion_url': page.get('url', ''),
                    'last_edited': page.get('last_edited_time', '')
                }
            }
            
            return event
            
        except Exception as e:
            print(f"âŒ Error converting page: {e}")
            return None
    
    def _extract_title(self, properties: Dict) -> Optional[str]:
        """í˜ì´ì§€ì—ì„œ ì œëª© ì¶”ì¶œ"""
        # ì¼ë°˜ì ì¸ ì œëª© ì†ì„±ëª…ë“¤
        title_keys = ['Name', 'Title', 'ì œëª©', 'Task', 'ì‘ì—…', 'Event', 'ì´ë²¤íŠ¸', 'í• ì¼']
        
        for key in title_keys:
            if key in properties:
                prop = properties[key]
                if prop.get('type') == 'title' and prop.get('title'):
                    return prop['title'][0].get('plain_text', '')
                elif prop.get('type') == 'rich_text' and prop.get('rich_text'):
                    return prop['rich_text'][0].get('plain_text', '')
        
        # ì²« ë²ˆì§¸ title íƒ€ì… ì†ì„± ì‚¬ìš©
        for prop_name, prop_data in properties.items():
            if prop_data.get('type') == 'title' and prop_data.get('title'):
                return prop_data['title'][0].get('plain_text', '')
        
        return None
    
    def _extract_date(self, properties: Dict) -> Optional[Dict]:
        """í˜ì´ì§€ì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ - ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ëª¨ë“  ë‚ ì§œ íƒ€ì… ì†ì„± í™•ì¸"""
        try:
            # ë¨¼ì € ì¼ë°˜ì ì¸ ë‚ ì§œ ì†ì„±ëª…ë“¤ì„ í™•ì¸
            common_date_keys = ['Date', 'Due', 'When', 'ë‚ ì§œ', 'ì¼ì •', 'Start', 'End', 'ì‹œì‘', 'ì¢…ë£Œ', 'Deadline', 'Created', 'Updated']
            
            for key in common_date_keys:
                if key in properties and properties[key].get('type') == 'date':
                    date_prop = properties[key].get('date')
                    if date_prop:
                        start = date_prop.get('start')
                        end = date_prop.get('end') or start
                        
                        if start:
                            # ì‹œê°„ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¢…ì¼ ì´ë²¤íŠ¸
                            all_day = 'T' not in start
                            
                            return {
                                'start': start,
                                'end': end,
                                'all_day': all_day
                            }
            
            # ì¼ë°˜ì ì¸ ì´ë¦„ìœ¼ë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš°, ëª¨ë“  ì†ì„±ì„ ìˆœíšŒí•˜ì—¬ ë‚ ì§œ íƒ€ì… ì°¾ê¸°
            for prop_name, prop_data in properties.items():
                if prop_data.get('type') == 'date' and prop_data.get('date'):
                    date_prop = prop_data.get('date')
                    start = date_prop.get('start')
                    end = date_prop.get('end') or start
                    
                    if start:
                        all_day = 'T' not in start
                        print(f"âœ… Found date property '{prop_name}': {start} â†’ {end}")
                        
                        return {
                            'start': start,
                            'end': end,
                            'all_day': all_day
                        }
        
        except Exception as e:
            print(f"âš ï¸ Error extracting date from properties: {e}")
        
        return None
    
    def _normalize_datetime(self, date_info: Dict) -> tuple:
        """ë‚ ì§œ/ì‹œê°„ì„ ì •ê·œí™”í•˜ê³  ê²€ì¦"""
        try:
            start_str = date_info['start']
            end_str = date_info['end']
            
            # ISO í˜•ì‹ íŒŒì‹±
            from datetime import datetime, timedelta
            import re
            
            # ì‹œê°„ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_time = 'T' in start_str
            
            if has_time:
                # ì‹œê°„ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                try:
                    # Handle various timezone formats
                    if start_str.endswith('Z'):
                        start_dt = datetime.fromisoformat(start_str.replace('Z', '+00:00'))
                        end_dt = datetime.fromisoformat(end_str.replace('Z', '+00:00'))
                    elif '+' in start_str and start_str.count('+') == 1:
                        # Handle +09:00 format
                        start_dt = datetime.fromisoformat(start_str)
                        end_dt = datetime.fromisoformat(end_str)
                    elif '.' in start_str and start_str.endswith('+09:00'):
                        # Handle .000+09:00 format specifically
                        start_dt = datetime.fromisoformat(start_str)
                        end_dt = datetime.fromisoformat(end_str)
                    else:
                        # No timezone, assume UTC
                        start_dt = datetime.fromisoformat(start_str + '+00:00')
                        end_dt = datetime.fromisoformat(end_str + '+00:00')
                except ValueError as parse_error:
                    print(f"âš ï¸ [NORMALIZE] Datetime parsing error: {parse_error}")
                    # Fallback: try to parse without timezone and add UTC
                    base_start = start_str.split('+')[0].split('Z')[0]
                    base_end = end_str.split('+')[0].split('Z')[0]
                    start_dt = datetime.fromisoformat(base_start + '+00:00')
                    end_dt = datetime.fromisoformat(base_end + '+00:00')
            else:
                # ë‚ ì§œë§Œ ìˆëŠ” ê²½ìš° (ì¢…ì¼ ì´ë²¤íŠ¸)
                start_dt = datetime.fromisoformat(start_str + 'T00:00:00+00:00')
                end_dt = datetime.fromisoformat(end_str + 'T23:59:59+00:00')
            
            # Date validation
            
            # CRITICAL: Prevent constraint violations with multiple validation layers
            # Validate date order
            
            # Convert to UTC for reliable comparison if needed
            if start_dt.tzinfo and end_dt.tzinfo:
                start_utc = start_dt.astimezone(timezone.utc)
                end_utc = end_dt.astimezone(timezone.utc)
                # UTC conversion for comparison
            else:
                start_utc, end_utc = start_dt, end_dt
            
            # Primary fix: end must be after start
            if end_utc <= start_utc:
                # Fix constraint violation: end <= start
                if not has_time:
                    # All-day events: ensure 24-hour span
                    start_dt = start_dt.replace(hour=0, minute=0, second=0, microsecond=0)
                    end_dt = start_dt + timedelta(days=1)
                    # Fixed all-day event duration
                else:
                    # Timed events: minimum 1-hour duration
                    end_dt = start_dt + timedelta(hours=1)
                    # Fixed timed event duration
            
            # Secondary safety check: after fixing, verify again
            end_final_utc = end_dt.astimezone(timezone.utc) if end_dt.tzinfo else end_dt
            start_final_utc = start_dt.astimezone(timezone.utc) if start_dt.tzinfo else start_dt
            
            if end_final_utc <= start_final_utc:
                # Secondary fix: 2-hour duration
                end_dt = start_dt + timedelta(hours=2)
            
            # Final absolute guarantee: never allow equality
            if end_dt == start_dt:
                # Emergency fix: add 10 minutes
                end_dt = start_dt + timedelta(minutes=10)
            
            # ISO í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            result_start = start_dt.isoformat()
            result_end = end_dt.isoformat()
            
            # Date normalization complete
            return result_start, result_end
            
        except Exception as e:
            print(f"âŒ Error normalizing datetime: {e}")
            print(f"ğŸ“Š Error details: start={date_info.get('start')}, end={date_info.get('end')}")
            
            # ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜ (1ì‹œê°„ duration)
            now = datetime.now(timezone.utc)
            start_default = now.isoformat()
            end_default = (now + timedelta(hours=1)).isoformat()
            
            # Using safe default dates
            return start_default, end_default
    
    def _extract_description(self, properties: Dict) -> Optional[str]:
        """í˜ì´ì§€ì—ì„œ ì„¤ëª… ì¶”ì¶œ"""
        desc_keys = ['Description', 'Notes', 'ì„¤ëª…', 'ë©”ëª¨', 'Details', 'ìƒì„¸', 'Content']
        
        for key in desc_keys:
            if key in properties:
                prop = properties[key]
                if prop.get('type') == 'rich_text' and prop.get('rich_text'):
                    texts = [t.get('plain_text', '') for t in prop['rich_text']]
                    return ' '.join(texts)
        
        return None
    
    def _normalize_uuid(self, uuid_str: str) -> str:
        """UUIDë¥¼ DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™” (í•˜ì´í”ˆ ì—†ëŠ” í˜•ì‹)"""
        if not uuid_str:
            return uuid_str
            
        # ì´ë©”ì¼ì´ UUIDë¡œ ì˜ëª» ì¸ì‹ëœ ê²½ìš° ì²˜ë¦¬
        if '@' in uuid_str:
            print(f"âš ï¸ [UUID] Email detected instead of UUID: {uuid_str}")
            # ì´ë©”ì¼ì—ì„œ UUID ìƒì„± (ì¼ê´€ì„±ì„ ìœ„í•´)
            import hashlib
            email_hash = hashlib.md5(uuid_str.encode()).hexdigest()
            # DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•˜ì´í”ˆ ì—†ìŒ)
            uuid_str = email_hash
            # Generated UUID from email
            return uuid_str
            
        # í•˜ì´í”ˆ ì œê±° í›„ ì¬í¬ë§·
        clean_uuid = uuid_str.replace('-', '')
        
        # 32ìë¦¬ hex ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ì—ëŸ¬
        if len(clean_uuid) != 32:
            print(f"âš ï¸ [UUID] Invalid UUID length: {len(clean_uuid)} (expected 32)")
            return uuid_str
            
        # DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ í¬ë§· (í•˜ì´í”ˆ ì—†ìŒ)
        formatted_uuid = clean_uuid.lower()
        
        if formatted_uuid != uuid_str.replace('-', '').lower():
            # UUID normalized
            pass
            
        return formatted_uuid

    def _get_user_primary_calendar_id(self, user_id: str) -> Optional[str]:
        """Get user's primary calendar ID (first calendar or default)"""
        try:
            from utils.config import config
            from utils.uuid_helper import normalize_uuid
            
            # Normalize user_id for consistency
            normalized_user_id = normalize_uuid(user_id)
            
            # Use admin client to bypass RLS
            supabase = config.supabase_admin if hasattr(config, 'supabase_admin') and config.supabase_admin else config.get_client_for_user(user_id)
            
            if not supabase:
                print(f"âŒ [PRIMARY_CAL] No Supabase client for user {user_id}")
                return None
            
            # Get user's first calendar (using owner_id field)
            result = supabase.table('calendars').select('id').eq('owner_id', normalized_user_id).order('created_at').limit(1).execute()
            
            if result.data:
                calendar_id = result.data[0]['id']
                print(f"âœ… [PRIMARY_CAL] Found primary calendar: {calendar_id}")
                return calendar_id
            else:
                print(f"âš ï¸ [PRIMARY_CAL] No calendar found for user {normalized_user_id}")
                return None
                
        except Exception as e:
            print(f"âŒ [PRIMARY_CAL] Error getting primary calendar ID: {e}")
            return None

    def _save_event_to_calendar(self, event: Dict) -> bool:
        """ì´ë²¤íŠ¸ë¥¼ NotionFlow ìº˜ë¦°ë”ì— ì €ì¥"""
        try:
            from utils.config import config
            from flask import session
            
            # Use admin client to bypass RLS policies
            supabase = config.supabase_admin if hasattr(config, 'supabase_admin') and config.supabase_admin else config.get_client_for_user(event['user_id'])
            
            if not supabase:
                print("âŒ Supabase client not available")
                return False
            
            # UUID ì •ê·œí™”
            user_id = self._normalize_uuid(event['user_id'])
            event['user_id'] = user_id  # ì •ê·œí™”ëœ UUIDë¡œ ì—…ë°ì´íŠ¸
            try:
                # Check if user exists in users table
                user_check = supabase.table('users').select('id').eq('id', user_id).execute()
                
                if not user_check.data:
                    # Creating user record
                    # Get user email from session or platform tokens
                    user_email = session.get('user_email')
                    if not user_email:
                        # Try to get from platform tokens in session
                        platform_tokens = session.get('platform_tokens', {})
                        notion_info = platform_tokens.get('notion', {})
                        user_email = notion_info.get('user_email') or f'{user_id[:8]}@notionflow.app'
                    
                    # Create user using proper helper function
                    from utils.uuid_helper import ensure_auth_user_exists
                    if ensure_auth_user_exists(user_id, user_email, 'Notion User'):
                        # User record created/verified
                        pass
                    else:
                        print("Error: Failed to create user record")
                        return False
                else:
                    # User record verified
                    pass
            except Exception as user_e:
                print(f"Error: Critical user error - {user_e}")
                return False
            
            # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì´ë²¤íŠ¸ ë°ì´í„° ë³€í™˜
            db_event = {
                'user_id': event['user_id'],
                'title': event['title'],
                'description': event.get('description', ''),
                'start_datetime': event['start_datetime'],
                'end_datetime': event['end_datetime'],
                'is_all_day': event.get('all_day', False),
                'category': 'notion',  # ì‹¤ì œ ìŠ¤í‚¤ë§ˆ í•„ë“œëª…
                'priority': 1,  # integer íƒ€ì… (0=low, 1=medium, 2=high)
                'status': 'confirmed',
                'source_platform': 'notion',  # ì‹¤ì œ ìŠ¤í‚¤ë§ˆ í•„ë“œëª…
                'external_id': event['external_id']  # ì‹¤ì œ ìŠ¤í‚¤ë§ˆ í•„ë“œëª…
                # created_at, updated_atëŠ” DEFAULT NOW()ë¡œ ìë™ ì„¤ì •
            }
            
            # CRITICAL FIX: calendar_id ì„¤ì • (í•­ìƒ ì„¤ì •ë˜ì–´ì•¼ í•¨)
            if 'calendar_id' in event and event['calendar_id']:
                db_event['calendar_id'] = event['calendar_id']
                # Using event calendar_id
            else:
                # calendar_idê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì˜ ì²« ë²ˆì§¸ ìº˜ë¦°ë”ë¡œ ì„¤ì •
                # Getting primary calendar for event
                
                # Get user's primary calendar
                primary_calendar_id = self._get_user_primary_calendar_id(user_id)
                if primary_calendar_id:
                    db_event['calendar_id'] = primary_calendar_id
                    # Using primary calendar
                else:
                    print(f"Warning: No calendar found for user {user_id}")
                    # Don't save orphaned events
                    return False
            
            # ULTRA-CRITICAL: Final datetime validation with timezone awareness
            from datetime import datetime, timedelta, timezone
            try:
                # Parse with proper timezone handling
                start_str = db_event['start_datetime']
                end_str = db_event['end_datetime']
                
                # Final date validation
                
                # Handle various timezone formats in the final check
                if start_str.endswith('Z'):
                    start_dt = datetime.fromisoformat(start_str.replace('Z', '+00:00'))
                    end_dt = datetime.fromisoformat(end_str.replace('Z', '+00:00'))
                elif '+' in start_str or '-' in start_str[-6:]:
                    start_dt = datetime.fromisoformat(start_str)
                    end_dt = datetime.fromisoformat(end_str)
                else:
                    start_dt = datetime.fromisoformat(start_str + '+00:00')
                    end_dt = datetime.fromisoformat(end_str + '+00:00')
                
                # Date parsing validation
                
                # Convert to UTC for reliable comparison
                start_utc = start_dt.astimezone(timezone.utc) if start_dt.tzinfo else start_dt
                end_utc = end_dt.astimezone(timezone.utc) if end_dt.tzinfo else end_dt
                
                # UTC time comparison validation
                
                # ABSOLUTE CONSTRAINT VIOLATION CHECK
                if end_utc <= start_utc:
                    # Critical: fixing constraint violation
                    
                    # Force minimum duration based on event type
                    if db_event.get('is_all_day', False):
                        # All-day: 24 hours minimum
                        end_dt = start_dt + timedelta(days=1)
                        # Fixed all-day event duration
                    else:
                        # Timed: 2 hours minimum (extra safe)
                        end_dt = start_dt + timedelta(hours=2)
                        # Fixed timed event duration
                    
                    db_event['end_datetime'] = end_dt.isoformat()
                    # Constraint violation fixed
                
                # Triple-check: verify the fix worked
                final_start = datetime.fromisoformat(db_event['start_datetime'].replace('Z', '+00:00') if 'Z' in db_event['start_datetime'] else db_event['start_datetime'])
                final_end = datetime.fromisoformat(db_event['end_datetime'].replace('Z', '+00:00') if 'Z' in db_event['end_datetime'] else db_event['end_datetime'])
                
                if final_start.tzinfo:
                    final_start_utc = final_start.astimezone(timezone.utc)
                    final_end_utc = final_end.astimezone(timezone.utc)
                else:
                    final_start_utc, final_end_utc = final_start, final_end
                
                if final_end_utc <= final_start_utc:
                    # Using emergency time fallback
                    now = datetime.now(timezone.utc)
                    db_event['start_datetime'] = now.isoformat()
                    db_event['end_datetime'] = (now + timedelta(hours=3)).isoformat()
                
                # Event times validated
                    
            except Exception as e:
                print(f"Error: Date validation failed - {e}")
                # Emergency fallback: guaranteed safe times
                now = datetime.now(timezone.utc)
                db_event['start_datetime'] = now.isoformat()
                db_event['end_datetime'] = (now + timedelta(hours=3)).isoformat()
                # Emergency fallback applied
            
            # Saving event to database
            
            # ì¤‘ë³µ ì²´í¬ (ì‹¤ì œ ìŠ¤í‚¤ë§ˆì˜ unique constraintì— ë§ì¶¤: user_id, external_id, source_platform)
            try:
                existing = supabase.table('calendar_events').select('id').eq(
                    'user_id', event['user_id']
                ).eq('external_id', event['external_id']).eq(
                    'source_platform', 'notion'
                ).execute()
                
                if existing.data:
                    # ê¸°ì¡´ ì´ë²¤íŠ¸ ì—…ë°ì´íŠ¸
                    # Updating existing event
                    result = supabase.table('calendar_events').update({
                        'title': db_event['title'],
                        'description': db_event['description'],
                        'start_datetime': db_event['start_datetime'],
                        'end_datetime': db_event['end_datetime'],
                        'is_all_day': db_event['is_all_day'],
                        'updated_at': datetime.now().isoformat()  # ë™ì ìœ¼ë¡œ í˜„ì¬ ì‹œê°„ ì„¤ì •
                    }).eq('id', existing.data[0]['id']).execute()
                    print(f"âœ… Updated existing event: {db_event['title']}")
                else:
                    # ìƒˆ ì´ë²¤íŠ¸ ìƒì„±
                    # Creating new event
                    result = supabase.table('calendar_events').insert(db_event).execute()
                    print(f"âœ… Created new event: {db_event['title']}")
                
                return bool(result.data)
            except Exception as save_error:
                print(f"Error saving event '{db_event['title']}': {save_error}")
                return False
            
        except Exception as e:
            print(f"âŒ Error saving event: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _save_events_batch(self, events: List[Dict]) -> int:
        """ë°°ì¹˜ë¡œ ì´ë²¤íŠ¸ë“¤ì„ NotionFlow ìº˜ë¦°ë”ì— ì €ì¥ - DB ì—°ê²° ìµœì í™”"""
        if not events:
            return 0

        try:
            from utils.config import config
            from datetime import datetime, timezone

            # Use admin client to bypass RLS policies
            supabase = config.supabase_admin if hasattr(config, 'supabase_admin') and config.supabase_admin else config.get_client_for_user(events[0]['user_id'])

            if not supabase:
                print("âŒ [BATCH] Supabase client not available")
                return 0

            saved_count = 0
            batch_data = []
            update_data = []

            print(f"ğŸ’¾ [BATCH] Processing {len(events)} events")

            # 1. ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•œ ê¸°ì¡´ ì´ë²¤íŠ¸ ì¡°íšŒ (í•œ ë²ˆì˜ ì¿¼ë¦¬ë¡œ)
            user_id = self._normalize_uuid(events[0]['user_id'])
            external_ids = [event['external_id'] for event in events]

            existing_result = supabase.table('calendar_events').select('id, external_id').eq(
                'user_id', user_id
            ).eq('source_platform', 'notion').in_('external_id', external_ids).execute()

            existing_external_ids = {item['external_id']: item['id'] for item in existing_result.data} if existing_result.data else {}

            print(f"ğŸ” [BATCH] Found {len(existing_external_ids)} existing events to update")

            # 2. ì´ë²¤íŠ¸ë³„ë¡œ ì²˜ë¦¬ (ìƒˆë¡œ ìƒì„±í•  ê²ƒê³¼ ì—…ë°ì´íŠ¸í•  ê²ƒ ë¶„ë¦¬)
            for event in events:
                try:
                    # UUID ì •ê·œí™”
                    user_id = self._normalize_uuid(event['user_id'])
                    event['user_id'] = user_id

                    # CRITICAL FIX: calendar_id ë°˜ë“œì‹œ ì„¤ì •
                    if not event.get('calendar_id'):
                        primary_calendar_id = self._get_user_primary_calendar_id(user_id)
                        if primary_calendar_id:
                            event['calendar_id'] = primary_calendar_id
                            print(f"ğŸ¯ [BATCH] Auto-assigned calendar_id: {primary_calendar_id}")
                        else:
                            print(f"âš ï¸ [BATCH] No calendar found for user {user_id}, skipping event")
                            continue

                    # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì´ë²¤íŠ¸ ë°ì´í„° ë³€í™˜
                    db_event = {
                        'user_id': event['user_id'],
                        'calendar_id': event['calendar_id'],  # CRITICAL: í•­ìƒ ì„¤ì •
                        'title': event['title'],
                        'description': event.get('description', ''),
                        'start_datetime': event['start_datetime'],
                        'end_datetime': event['end_datetime'],
                        'is_all_day': event.get('all_day', False),
                        'category': 'notion',
                        'priority': 1,
                        'status': 'confirmed',
                        'source_platform': 'notion',
                        'external_id': event['external_id']
                    }

                    # ê¸°ì¡´ ì´ë²¤íŠ¸ì¸ì§€ í™•ì¸
                    if event['external_id'] in existing_external_ids:
                        # ì—…ë°ì´íŠ¸ìš© ë°ì´í„° ì¤€ë¹„
                        db_event['updated_at'] = datetime.now().isoformat()
                        update_data.append({
                            'id': existing_external_ids[event['external_id']],
                            'data': db_event
                        })
                    else:
                        # ìƒˆ ì´ë²¤íŠ¸ìš© ë°ì´í„° ì¤€ë¹„
                        batch_data.append(db_event)

                except Exception as event_error:
                    print(f"âŒ [BATCH] Error processing event {event.get('title', 'Unknown')}: {event_error}")
                    continue

            # 3. ë°°ì¹˜ ì‚½ì… (ìƒˆ ì´ë²¤íŠ¸ë“¤)
            if batch_data:
                try:
                    insert_result = supabase.table('calendar_events').insert(batch_data).execute()
                    inserted_count = len(insert_result.data) if insert_result.data else 0
                    saved_count += inserted_count
                    print(f"âœ… [BATCH INSERT] Created {inserted_count} new events")
                except Exception as insert_error:
                    print(f"âŒ [BATCH INSERT] Failed: {insert_error}")

            # 4. ë°°ì¹˜ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ì´ë²¤íŠ¸ë“¤) - ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
            updated_count = 0
            for update_item in update_data:
                try:
                    # Remove id and updated_at from data for update
                    update_data_clean = {k: v for k, v in update_item['data'].items() if k not in ['id', 'created_at']}
                    update_result = supabase.table('calendar_events').update(update_data_clean).eq('id', update_item['id']).execute()
                    if update_result.data:
                        updated_count += 1
                except Exception as update_error:
                    print(f"âŒ [BATCH UPDATE] Failed for event {update_item['id']}: {update_error}")

            saved_count += updated_count
            print(f"âœ… [BATCH UPDATE] Updated {updated_count} existing events")

            print(f"ğŸ’¾ [BATCH COMPLETE] Total saved: {saved_count}/{len(events)} events")
            return saved_count

        except Exception as e:
            print(f"âŒ [BATCH] Error saving batch: {e}")
            import traceback
            traceback.print_exc()
            return 0

    def _schedule_cache_warmup(self, user_id: str, calendar_id: str):
        """PERFORMANCE: ìºì‹œ ì›Œë°ì—…ì„ ìœ„í•œ ë°±ê·¸ë¼ìš´ë“œ í”„ë¦¬ë¡œë”© ì˜ˆì•½"""
        try:
            import threading
            import time

            def cache_warmup_worker():
                try:
                    # 3ì´ˆ í›„ ìºì‹œ ì›Œë°ì—… ì‹¤í–‰ (UI ì‘ë‹µì„± í™•ë³´)
                    time.sleep(3)
                    print(f"ğŸš€ [CACHE WARMUP] Starting for user {user_id}")

                    # ìºì‹œìš© ì´ë²¤íŠ¸ ì¡°íšŒ ë° ì €ì¥
                    from utils.config import config
                    supabase = config.supabase_admin if hasattr(config, 'supabase_admin') and config.supabase_admin else config.get_client_for_user(user_id)

                    if supabase:
                        # í–¥í›„ 30ì¼ê°„ì˜ ì´ë²¤íŠ¸ë¥¼ ë¯¸ë¦¬ ìºì‹œ
                        from datetime import datetime, timedelta, timezone
                        start_date = datetime.now(timezone.utc)
                        end_date = start_date + timedelta(days=30)

                        # ìºì‹œ í…Œì´ë¸”ì— ì´ë²¤íŠ¸ ì •ë³´ ì €ì¥ (ë¯¸ë˜ í™•ì¥ìš©)
                        cache_result = supabase.table('calendar_events').select('id, title, start_datetime, end_datetime').eq(
                            'user_id', user_id
                        ).eq('calendar_id', calendar_id).gte(
                            'start_datetime', start_date.isoformat()
                        ).lte(
                            'start_datetime', end_date.isoformat()
                        ).execute()

                        cached_count = len(cache_result.data) if cache_result.data else 0
                        print(f"âœ… [CACHE WARMUP] Cached {cached_count} events for faster access")

                except Exception as warmup_error:
                    print(f"âš ï¸ [CACHE WARMUP] Error: {warmup_error}")

            # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
            cache_thread = threading.Thread(target=cache_warmup_worker, daemon=True)
            cache_thread.start()
            print(f"ğŸ¯ [CACHE WARMUP] Scheduled for user {user_id}")

        except Exception as e:
            print(f"âŒ [CACHE WARMUP] Scheduling failed: {e}")

    def _schedule_background_sync(self, user_id: str, calendar_id: str, access_token: str):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‚˜ë¨¸ì§€ ë°ì´í„° ë™ê¸°í™” ì˜ˆì•½"""
        try:
            import threading
            import time
            
            def background_sync():
                # 5ì´ˆ í›„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‚˜ë¨¸ì§€ ë™ê¸°í™” ì‹œì‘
                time.sleep(5)
                # Starting background sync
                
                try:
                    # ì „ì²´ ë™ê¸°í™” ì‹¤í–‰ (ì œí•œ ì—†ì´)
                    self._full_background_sync(user_id, calendar_id, access_token)
                except Exception as bg_error:
                    print(f"âŒ Background sync failed: {bg_error}")
            
            # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
            bg_thread = threading.Thread(target=background_sync, daemon=True)
            bg_thread.start()
            
            # Background sync scheduled
            
        except Exception as e:
            print(f"âŒ Failed to schedule background sync: {e}")

    def _full_background_sync(self, user_id: str, calendar_id: str, access_token: str):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì „ì²´ ë°ì´í„° ë™ê¸°í™” (ì œí•œ ì—†ì´)"""
        try:
            # Starting full background sync
            
            # Notion API ì´ˆê¸°í™”
            notion_api = NotionAPI(access_token)
            
            # ëª¨ë“  ìº˜ë¦°ë” ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
            calendar_dbs = self.find_calendar_databases(notion_api)
            
            if not calendar_dbs:
                print("ğŸ“­ No calendar databases found in background sync")
                return
            
            total_synced = 0
            
            for db in calendar_dbs:
                db_id = db['id']
                db_title = self._get_db_title(db)
                
                # Background processing database
                
                # ì´ë¯¸ ë™ê¸°í™”ëœ ì´ë²¤íŠ¸ í™•ì¸ (ì¤‘ë³µ ë°©ì§€)
                start_cursor = None
                
                while True:
                    result = notion_api.query_database_safe(db_id, page_size=50, start_cursor=start_cursor)
                    pages = result.get('results', [])
                    
                    if not pages:
                        break
                    
                    for page in pages:
                        # ì¤‘ë³µ í™•ì¸
                        if not self._is_event_already_synced(page, calendar_id, user_id):
                            event = self._convert_page_to_event(page, calendar_id, user_id)
                            
                            if event and self._save_event_to_calendar(event):
                                total_synced += 1
                                if total_synced % 10 == 0:  # 10ê°œë§ˆë‹¤ ë¡œê·¸
                                    pass  # Background sync progress
                    
                    if not result.get('has_more', False):
                        break
                    
                    start_cursor = result.get('next_cursor')
                    
                    # ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ë¶€í•˜ ë°©ì§€
                    import gc
                    gc.collect()
                    time.sleep(0.5)
            
            print(f"âœ… Background sync completed: {total_synced} additional events synced")
            
        except Exception as e:
            print(f"âŒ Full background sync failed: {e}")

    def _is_event_already_synced(self, notion_page: Dict, calendar_id: str, user_id: str) -> bool:
        """ì´ë²¤íŠ¸ê°€ ì´ë¯¸ ë™ê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        try:
            from utils.config import config
            supabase = config.get_client_for_user(user_id)
            
            notion_page_id = notion_page.get('id', '')
            
            # ì´ë¯¸ ë™ê¸°í™”ëœ ì´ë²¤íŠ¸ì¸ì§€ í™•ì¸ (ì‹¤ì œ ìŠ¤í‚¤ë§ˆ í•„ë“œëª… ì‚¬ìš©)
            existing = supabase.table('calendar_events').select('id').eq(
                'user_id', user_id
            ).eq('external_id', notion_page_id).eq('source_platform', 'notion').execute()
            
            return len(existing.data) > 0
            
        except Exception as e:
            print(f"âŒ Error checking if event already synced: {e}")
            return False


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
notion_sync = NotionCalendarSync()